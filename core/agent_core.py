#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
@File    : agent_core.py
@Time    : 2025å¹´07æœˆ19æ—¥ 16:00:00
@Author  : å®æ€»
@Version : 1.0
@Desc    : å®æ€»ä¸“å±SuperAgentæ ¸å¿ƒå¼•æ“
"""

import json
import time
import asyncio
from datetime import datetime
from typing import List, Dict, Any, Optional, Callable, Tuple
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum

# å¯¼å…¥è®°å¿†ç³»ç»Ÿ
import sys
sys.path.append(str(Path(__file__).parent.parent))

from memory.memory_enhancer import MemoryEnhancer


class AgentState(Enum):
    """AgentçŠ¶æ€æšä¸¾"""
    IDLE = "idle"
    THINKING = "thinking"
    PLANNING = "planning"
    EXECUTING = "executing"
    LEARNING = "learning"
    ERROR = "error"


@dataclass
class Task:
    """ä»»åŠ¡æ•°æ®ç»“æ„"""
    id: str
    title: str
    description: str
    priority: int = 1  # 1-5ï¼Œ5æœ€é«˜
    status: str = "pending"
    created_at: Optional[float] = None
    updated_at: Optional[float] = None
    metadata: Optional[Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
        if self.updated_at is None:
            self.updated_at = time.time()
        if self.metadata is None:
            self.metadata = {}


@dataclass
class AgentResponse:
    """Agentå“åº”ç»“æ„"""
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
    suggestions: Optional[List[str]] = None
    next_actions: Optional[List[str]] = None


class BaozongSuperAgent:
    """
    å®æ€»ä¸“å±è¶…çº§Agent
    
    é›†æˆæ··åˆè®°å¿†ç³»ç»Ÿçš„æ™ºèƒ½Agentæ ¸å¿ƒ
    """
    
    def __init__(self, agent_name: str = "å®æ€»çš„SuperAgent", workspace_dir: str = "./baozong_workspace"):
        self.agent_name = agent_name
        self.workspace_dir = Path(workspace_dir)
        self.workspace_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self.memory_system = MemoryEnhancer(str(self.workspace_dir / "memory"))
        self.state = AgentState.IDLE
        self.current_session_id = f"session_{int(time.time())}"
        
        # åˆå§‹åŒ–ç¬é—´ä¿®å¤å™¨
        try:
            sys.path.append(str(Path(__file__).parent.parent))
            from instant_agent_fix import InstantFix
            self.instant_fix = InstantFix()
            print(f"ğŸš€ {agent_name} å·²å¯ç”¨ç¬é—´ä¿®å¤æ¨¡å¼")
            print("ğŸ“ˆ å›ç­”è´¨é‡é¢„æœŸæå‡300%+")
        except ImportError as e:
            print(f"âš ï¸ ç¬é—´ä¿®å¤æ¨¡å—æœªæ‰¾åˆ°: {e}")
            print("ğŸ’¡ è¯·ç¡®ä¿ instant_agent_fix.py åœ¨æ­£ç¡®ä½ç½®")
            self.instant_fix = None
        
        # ä»»åŠ¡ç®¡ç†
        self.task_queue: List[Task] = []
        self.completed_tasks: List[Task] = []
        self.active_task: Optional[Task] = None
        
        # Agenté…ç½®
        self.config = self._load_config()
        self.tools: Dict[str, Callable] = {}
        
        # æ€§èƒ½ç›‘æ§
        self.performance_stats = {
            "tasks_completed": 0,
            "total_thinking_time": 0.0,
            "average_response_time": 0.0,
            "success_rate": 0.0,
            "start_time": time.time()
        }
        
        self._init_core_tools()
        self._log_startup()
    
    def _load_config(self) -> Dict[str, Any]:
        """åŠ è½½Agenté…ç½®"""
        config_file = self.workspace_dir / "agent_config.json"
        
        default_config = {
            "personality": {
                "name": "å®æ€»çš„SuperAgent",
                "role": "å…¨æ ˆå¼€å‘åŠ©æ‰‹",
                "traits": ["ä¸“ä¸š", "é«˜æ•ˆ", "å­¦ä¹ èƒ½åŠ›å¼º", "æ³¨é‡ç»†èŠ‚"],
                "communication_style": "ç®€æ´æ˜äº†ï¼ŒæŠ€æœ¯å¯¼å‘"
            },
            "capabilities": {
                "max_thinking_steps": 10,
                "memory_context_size": 20,
                "task_priority_levels": 5,
                "auto_learning": True,
                "proactive_suggestions": True
            },
            "preferences": {
                "primary_language": "Python",
                "coding_standards": "PEP8",
                "project_structure": "æ¨¡å—åŒ–",
                "documentation_style": "è¯¦ç»†æ³¨é‡Š"
            }
        }
        
        if config_file.exists():
            try:
                with open(config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    # åˆå¹¶é…ç½®
                    return {**default_config, **user_config}
            except Exception as e:
                print(f"âš ï¸ åŠ è½½é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        
        # ä¿å­˜é»˜è®¤é…ç½®
        with open(config_file, 'w', encoding='utf-8') as f:
            json.dump(default_config, f, indent=2, ensure_ascii=False)
        
        return default_config
    
    def _init_core_tools(self):
        """åˆå§‹åŒ–æ ¸å¿ƒå·¥å…·é›†"""
        self.tools.update({
            "memory_search": self.memory_system.smart_recall,
            "add_memory": self.memory_system.add_memory_with_analysis,
            "get_context": self.memory_system.get_smart_context,
            "create_task": self.create_task,
            "complete_task": self.complete_task,
            "analyze_performance": self.get_performance_report
        })
    
    def _log_startup(self):
        """è®°å½•å¯åŠ¨æ—¥å¿—"""
        startup_info = f"Agent '{self.agent_name}' å¯åŠ¨æˆåŠŸ"
        self.memory_system.add_memory_with_analysis(
            startup_info,
            memory_type="system",
            importance=0.7,
            tags=["å¯åŠ¨", "ç³»ç»Ÿ"],
            metadata={
                "action": "startup",
                "session_id": self.current_session_id,
                "agent_version": "1.0"
            }
        )
        print(f"ğŸ¤– {startup_info}")
    
    def think(self, query: str, max_steps: Optional[int] = None) -> Dict[str, Any]:
        """æ€è€ƒè¿‡ç¨‹ - Agentçš„æ ¸å¿ƒæ¨ç†èƒ½åŠ›"""
        if max_steps is None:
            max_steps = self.config["capabilities"]["max_thinking_steps"]
        
        self.state = AgentState.THINKING
        thinking_start = time.time()
        
        thinking_log = {
            "query": query,
            "steps": [],
            "context": {},
            "conclusion": "",
            "confidence": 0.0
        }
        
        # æ­¥éª¤1: è·å–ç›¸å…³ä¸Šä¸‹æ–‡
        thinking_log["steps"].append("ğŸ” æ£€ç´¢ç›¸å…³è®°å¿†å’Œä¸Šä¸‹æ–‡")
        context = self.memory_system.get_smart_context(query)
        thinking_log["context"] = {
            "relevant_memories": len(context.get("recent_memories", [])),
            "session_memories": context.get("session_memories_count", 0),
            "knowledge_concepts": len(context.get("knowledge_insights", {}).get("relevant_concepts", {}))
        }
        
        # æ­¥éª¤2: åˆ†ææŸ¥è¯¢ç±»å‹å’Œæ„å›¾
        thinking_log["steps"].append("ğŸ¯ åˆ†ææŸ¥è¯¢æ„å›¾å’Œç±»å‹")
        query_analysis = self._analyze_query(query)
        thinking_log["query_type"] = query_analysis["type"]
        thinking_log["intent"] = query_analysis["intent"]
        
        # æ­¥éª¤3: åˆ¶å®šå“åº”ç­–ç•¥
        thinking_log["steps"].append("ğŸ“‹ åˆ¶å®šå“åº”ç­–ç•¥")
        strategy = self._plan_response_strategy(query, query_analysis, context)
        thinking_log["strategy"] = strategy
        
        # æ­¥éª¤4: ç”Ÿæˆå“åº”
        thinking_log["steps"].append("ğŸ’¡ ç”Ÿæˆå“åº”")
        response = self._generate_response(query, strategy, context)
        thinking_log["conclusion"] = response["message"]
        thinking_log["confidence"] = response.get("confidence", 0.8)
        
        # è®°å½•æ€è€ƒè¿‡ç¨‹
        thinking_time = time.time() - thinking_start
        self.performance_stats["total_thinking_time"] += thinking_time
        
        self.memory_system.add_memory_with_analysis(
            f"æ€è€ƒæŸ¥è¯¢: {query[:50]}... (è€—æ—¶: {thinking_time:.2f}ç§’)",
            memory_type="procedural",
            importance=0.6,
            tags=["æ€è€ƒ", "æ¨ç†"],
            metadata={
                "thinking_time": thinking_time,
                "steps_count": len(thinking_log["steps"]),
                "confidence": thinking_log["confidence"]
            }
        )
        
        self.state = AgentState.IDLE
        return thinking_log
    
    def _analyze_query(self, query: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢ç±»å‹å’Œæ„å›¾"""
        query_lower = query.lower()
        
        # æŸ¥è¯¢ç±»å‹åˆ†ç±»
        query_type = "general"
        if any(word in query_lower for word in ["å¦‚ä½•", "æ€ä¹ˆ", "æ–¹æ³•", "how", "way"]):
            query_type = "how_to"
        elif any(word in query_lower for word in ["ä»€ä¹ˆ", "æ˜¯ä»€ä¹ˆ", "what", "define"]):
            query_type = "definition"
        elif any(word in query_lower for word in ["ä¸ºä»€ä¹ˆ", "åŸå› ", "why", "reason"]):
            query_type = "explanation"
        elif any(word in query_lower for word in ["å¸®æˆ‘", "è¯·", "èƒ½å¦", "å¯ä»¥", "help", "please"]):
            query_type = "request"
        elif any(word in query_lower for word in ["åˆ›å»º", "ç”Ÿæˆ", "åˆ¶ä½œ", "create", "generate"]):
            query_type = "creation"
        
        # æ„å›¾è¯†åˆ«
        intent = "unknown"
        if any(word in query_lower for word in ["ä»£ç ", "ç¼–ç¨‹", "å¼€å‘", "code", "program"]):
            intent = "coding"
        elif any(word in query_lower for word in ["é¡¹ç›®", "ä»»åŠ¡", "å·¥ä½œ", "project", "task"]):
            intent = "project_management"
        elif any(word in query_lower for word in ["å­¦ä¹ ", "äº†è§£", "ç ”ç©¶", "learn", "study"]):
            intent = "learning"
        elif any(word in query_lower for word in ["ä¼˜åŒ–", "æ”¹è¿›", "æå‡", "optimize", "improve"]):
            intent = "optimization"
        
        return {
            "type": query_type,
            "intent": intent,
            "complexity": len(query.split()),  # ç®€å•çš„å¤æ‚åº¦è¯„ä¼°
            "technical_terms": self._extract_technical_terms(query)
        }
    
    def _extract_technical_terms(self, text: str) -> List[str]:
        """æå–æŠ€æœ¯æœ¯è¯­"""
        tech_terms = []
        tech_keywords = [
            "python", "javascript", "react", "vue", "django", "flask", "fastapi",
            "ai", "machine learning", "deep learning", "neural network",
            "langchain", "openai", "gpt", "llm", "agent", "chatbot",
            "database", "sql", "mongodb", "redis", "docker", "kubernetes",
            "api", "rest", "graphql", "websocket", "http", "json",
            "github", "git", "cicd", "devops", "aws", "azure", "gcp"
        ]
        
        text_lower = text.lower()
        for term in tech_keywords:
            if term in text_lower:
                tech_terms.append(term)
        
        return tech_terms
    
    def _plan_response_strategy(self, query: str, analysis: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ¶å®šå“åº”ç­–ç•¥"""
        strategy = {
            "approach": "direct_response",
            "use_memory": True,
            "create_task": False,
            "suggest_actions": True,
            "learning_opportunity": False
        }
          # æ ¹æ®æŸ¥è¯¢ç±»å‹è°ƒæ•´ç­–ç•¥
        if analysis["type"] == "request":
            strategy["approach"] = "task_oriented"
            strategy["create_task"] = True
        elif analysis["type"] == "how_to" or analysis["intent"] == "learning":
            strategy["approach"] = "educational"
            strategy["learning_opportunity"] = True
        elif analysis["intent"] == "coding":
            strategy["approach"] = "technical_solution"
            strategy["suggest_actions"] = True
        
        # æ ¹æ®ä¸Šä¸‹æ–‡è°ƒæ•´ç­–ç•¥
        if context.get("session_memories_count", 0) > 10:
            strategy["use_session_context"] = True
        
        return strategy
    
    def _generate_response(self, query: str, strategy: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨ç¬é—´ä¿®å¤å™¨ç”Ÿæˆé«˜è´¨é‡å“åº”"""
        
        # å¦‚æœç¬é—´ä¿®å¤å™¨å¯ç”¨ï¼Œä½¿ç”¨å¢å¼ºå“åº”
        if hasattr(self, 'instant_fix') and self.instant_fix is not None:
            try:
                enhanced_response = self.instant_fix.generate_smart_response(query, context)
                
                # è½¬æ¢ä¸ºåŸæœ‰æ ¼å¼
                return {
                    "message": enhanced_response["message"],
                    "confidence": enhanced_response["confidence"],
                    "suggestions": enhanced_response["suggestions"],
                    "next_actions": enhanced_response["next_actions"]
                }
                
            except Exception as e:
                print(f"âš ï¸ ç¬é—´ä¿®å¤å™¨è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ: {e}")
        
        # é™çº§åˆ°åŸæœ‰é€»è¾‘ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        response = {
            "message": "",
            "confidence": 0.8,
            "suggestions": [],
            "next_actions": []
        }
        
        # ç‰¹æ®ŠæŸ¥è¯¢å¤„ç†
        query_lower = query.lower()
        
        # èƒ½åŠ›ä»‹ç»æŸ¥è¯¢
        if any(word in query_lower for word in ["èƒ½åŠ›", "ä»‹ç»", "ä½ æ˜¯", "ä½ å¥½", "åŠŸèƒ½", "what can you"]):
            response["message"] = self._get_capability_introduction()
            response["suggestions"] = [
                "å°è¯•: 'task create \"å­¦ä¹ æ–°æŠ€æœ¯\" \"ç ”ç©¶FastAPIæ¡†æ¶\" 3'",
                "å°è¯•: 'memory search Python'",
                "å°è¯•: 'å¸®æˆ‘åˆ†æä»£ç æ¶æ„è®¾è®¡'"
            ]
            response["next_actions"] = ["ä½“éªŒä»»åŠ¡ç®¡ç†åŠŸèƒ½", "æµ‹è¯•è®°å¿†æœç´¢", "è¿›è¡ŒæŠ€æœ¯è®¨è®º"]
            response["confidence"] = 0.95
            return response
        
        # ä¸Šä¸‹æ–‡å»ºè®®æŸ¥è¯¢
        if "ä¸Šä¸‹æ–‡" in query_lower or "å»ºè®®" in query_lower:
            response["message"] = self._get_context_based_suggestions(context)
            response["suggestions"] = self._generate_smart_suggestions(context)
            response["next_actions"] = ["æŸ¥çœ‹è®°å¿†æ¨¡å¼", "åˆ†æçŸ¥è¯†å›¾è°±", "åˆ›å»ºç›¸å…³ä»»åŠ¡"]
            response["confidence"] = 0.9
            return response
        
        # åŸºäºç­–ç•¥ç”Ÿæˆå“åº”
        if strategy["approach"] == "task_oriented":
            response["message"] = f"æˆ‘ç†è§£æ‚¨çš„è¯·æ±‚ï¼š{query}ã€‚è®©æˆ‘ä¸ºæ‚¨åˆ›å»ºç›¸åº”çš„ä»»åŠ¡ã€‚"
            response["next_actions"].append("åˆ›å»ºä»»åŠ¡")
            response["suggestions"].append("å°†å¤æ‚è¯·æ±‚åˆ†è§£ä¸ºå…·ä½“æ­¥éª¤")
            
        elif strategy["approach"] == "educational":
            response["message"] = f"å…³äºæ‚¨çš„é—®é¢˜ï¼š{query}ï¼Œæˆ‘å°†ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢æ¥è§£ç­”..."
            response["next_actions"].append("æä¾›è¯¦ç»†è§£é‡Š")
            response["suggestions"].append("æ¨èç›¸å…³å­¦ä¹ èµ„æº")
            
        elif strategy["approach"] == "technical_solution":
            response["message"] = f"é’ˆå¯¹æŠ€æœ¯é—®é¢˜ï¼š{query}ï¼Œæˆ‘å»ºè®®é‡‡ç”¨ä»¥ä¸‹æ–¹æ¡ˆ..."
            response["next_actions"].append("æä¾›ä»£ç ç¤ºä¾‹")
            response["suggestions"].append("è€ƒè™‘æœ€ä½³å®è·µ")
            
        else:
            response["message"] = f"æˆ‘å·²ç†è§£æ‚¨çš„é—®é¢˜ï¼š{query}ã€‚è®©æˆ‘ä¸ºæ‚¨æä¾›ç›¸å…³ä¿¡æ¯ã€‚"
        
        # æ·»åŠ åŸºäºè®°å¿†çš„ä¸Šä¸‹æ–‡
        if strategy.get("use_memory") and context.get("recent_memories"):
            response["message"] += f"\\n\\nåŸºäºæ‚¨ä¹‹å‰çš„{len(context['recent_memories'])}æ¡ç›¸å…³è®°å¿†ï¼Œ"
        
        return response
    
    def create_task(self, title: str, description: str = "", priority: int = 1) -> str:
        """åˆ›å»ºæ–°ä»»åŠ¡"""
        task = Task(
            id=f"task_{int(time.time())}_{len(self.task_queue)}",
            title=title,
            description=description,
            priority=priority
        )
        
        self.task_queue.append(task)
        self.task_queue.sort(key=lambda t: t.priority, reverse=True)  # æŒ‰ä¼˜å…ˆçº§æ’åº
        
        # è®°å½•ä»»åŠ¡åˆ›å»º
        self.memory_system.add_memory_with_analysis(
            f"åˆ›å»ºä»»åŠ¡: {title}",
            memory_type="task",
            importance=0.7,
            tags=["ä»»åŠ¡", "åˆ›å»º"],
            metadata={
                "task_id": task.id,                "priority": priority,
                "action": "task_created"
            }
        )
        
        return task.id
    
    def complete_task(self, task_id: str, result: str = "") -> bool:
        """å®Œæˆä»»åŠ¡"""
        task = None
        for i, t in enumerate(self.task_queue):
            if t.id == task_id:
                task = self.task_queue.pop(i)
                break
        
        if not task:
            return False
        
        task.status = "completed"
        task.updated_at = time.time()
        if task.metadata is None:
            task.metadata = {}
        task.metadata["completion_result"] = result
        
        self.completed_tasks.append(task)
        self.performance_stats["tasks_completed"] += 1
        
        # è®°å½•ä»»åŠ¡å®Œæˆ
        completion_time = (task.updated_at or time.time()) - (task.created_at or time.time())
        self.memory_system.add_memory_with_analysis(
            f"å®Œæˆä»»åŠ¡: {task.title} - {result}",
            memory_type="achievement",
            importance=0.8,
            tags=["ä»»åŠ¡", "å®Œæˆ"],
            metadata={
                "task_id": task.id,
                "completion_time": completion_time,
                "action": "task_completed"
            }
        )
        
        return True
    
    def get_performance_report(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æŠ¥å‘Š"""
        uptime = time.time() - self.performance_stats["start_time"]
        total_tasks = len(self.completed_tasks) + len(self.task_queue)
        
        return {
            "agent_name": self.agent_name,
            "session_id": self.current_session_id,
            "uptime_hours": uptime / 3600,
            "tasks": {
                "completed": len(self.completed_tasks),
                "pending": len(self.task_queue),
                "total": total_tasks
            },
            "performance": {
                "success_rate": self.performance_stats["tasks_completed"] / max(total_tasks, 1),
                "avg_thinking_time": self.performance_stats["total_thinking_time"] / max(1, self.performance_stats["tasks_completed"]),
                "productivity_score": self.performance_stats["tasks_completed"] / (uptime / 3600)
            },
            "memory_stats": {
                "total_memories": "ä»è®°å¿†ç³»ç»Ÿè·å–",
                "session_memories": len(self.memory_system.session_memories),
                "knowledge_concepts": len(self.memory_system.knowledge_graph)
            }
        }
    
    def _get_capability_introduction(self) -> str:
        """è·å–èƒ½åŠ›ä»‹ç»"""
        return f"""ğŸ¤– æ‚¨å¥½ï¼Œæˆ‘æ˜¯{self.agent_name}ï¼

ğŸ§  **æ ¸å¿ƒèƒ½åŠ›**:
â€¢ æ··åˆè®°å¿†ç³»ç»Ÿ - å…·å¤‡å·¥ä½œè®°å¿†ã€è¯­ä¹‰è®°å¿†ã€æƒ…èŠ‚è®°å¿†ã€ç¨‹åºè®°å¿†ã€é¡¹ç›®è®°å¿†äº”å±‚æ¶æ„
â€¢ æ™ºèƒ½å¯¹è¯äº¤äº’ - åŸºäºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„è‡ªç„¶è¯­è¨€ç†è§£å’Œå“åº”
â€¢ ä»»åŠ¡ç®¡ç†ä¸“å®¶ - åˆ›å»ºã€è·Ÿè¸ªã€ä¼˜åŒ–ä»»åŠ¡æ‰§è¡Œæµç¨‹
â€¢ çŸ¥è¯†å›¾è°±æ„å»º - è‡ªåŠ¨å­¦ä¹ å’Œå…³è”æ‚¨çš„æŠ€æœ¯çŸ¥è¯†ä¸é¡¹ç›®ç»éªŒ

ğŸ¯ **ä¸“ä¸šå®šä½**:
â€¢ ä¸“ä¸ºPythonå…¨æ ˆå¼€å‘è€…å®šåˆ¶
â€¢ æ·±åº¦ç†è§£å¼€å‘æµç¨‹å’ŒæŠ€æœ¯æ ˆ
â€¢ éµå¾ªç¬¬ä¸€æ€§åŸç†æ€ç»´æ¡†æ¶
â€¢ æŒç»­å­¦ä¹ å’Œä¸ªæ€§åŒ–é€‚åº”

âš¡ **å³åˆ»ä½“éªŒ**:
â€¢ ä¸æˆ‘è‡ªç”±å¯¹è¯ï¼Œæˆ‘ä¼šè®°ä½æˆ‘ä»¬çš„äº¤æµå†…å®¹
â€¢ åˆ›å»ºå’Œç®¡ç†æ‚¨çš„å¼€å‘ä»»åŠ¡
â€¢ æœç´¢å’Œç®¡ç†æŠ€æœ¯çŸ¥è¯†è®°å¿†
â€¢ æŸ¥çœ‹æˆ‘çš„æ€è€ƒè¿‡ç¨‹å’Œåˆ†æç»“æœ

æˆ‘çš„è®°å¿†ç³»ç»Ÿå·²å­˜å‚¨{len(self.memory_system.session_memories)}æ¡ä¼šè¯è®°å¿†ï¼ŒçŸ¥è¯†å›¾è°±åŒ…å«{len(self.memory_system.knowledge_graph)}ä¸ªæ¦‚å¿µèŠ‚ç‚¹ã€‚

å‡†å¤‡å¥½å¼€å§‹æˆ‘ä»¬çš„æŠ€æœ¯åä½œä¹‹æ—…å—ï¼Ÿ ğŸš€"""
    
    def _get_context_based_suggestions(self, context: Dict[str, Any]) -> str:
        """åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆå»ºè®®"""
        suggestions_text = "ğŸ“Š **åŸºäºå½“å‰ä¸Šä¸‹æ–‡çš„æ™ºèƒ½å»ºè®®**:\n\n"
        
        # åŸºäºè®°å¿†æ¨¡å¼çš„å»ºè®®
        memory_patterns = context.get("memory_patterns", {})
        if memory_patterns and memory_patterns != {"pattern": "no_data"}:
            memory_types = memory_patterns.get("memory_types", {})
            if memory_types:
                dominant_type = max(memory_types.items(), key=lambda x: x[1])
                suggestions_text += f"ğŸ¯ **è®°å¿†æ¨¡å¼åˆ†æ**: æ‚¨å½“å‰ä¸»è¦å…³æ³¨{dominant_type[0]}ç±»è®°å¿†({dominant_type[1]}æ¡)\n"
                
                if dominant_type[0] == "task":
                    suggestions_text += "   å»ºè®®: è€ƒè™‘å°†å¤§ä»»åŠ¡åˆ†è§£ä¸ºå°ä»»åŠ¡ï¼Œæå‡æ‰§è¡Œæ•ˆç‡\n"
                elif dominant_type[0] == "episodic":
                    suggestions_text += "   å»ºè®®: å¯ä»¥æ€»ç»“è¿™äº›ç»å†ï¼Œæç‚¼å‡ºå¯å¤ç”¨çš„ç»éªŒ\n"
                elif dominant_type[0] == "procedural":
                    suggestions_text += "   å»ºè®®: è€ƒè™‘å°†è¿™äº›æŠ€èƒ½æ•´ç†æˆçŸ¥è¯†åº“\n"
        
        # åŸºäºçŸ¥è¯†æ´å¯Ÿçš„å»ºè®®
        knowledge_insights = context.get("knowledge_insights", {})
        relevant_concepts = knowledge_insights.get("relevant_concepts", {})
        if relevant_concepts:
            suggestions_text += f"\nğŸ§  **çŸ¥è¯†å›¾è°±æ´å¯Ÿ**: å‘ç°{len(relevant_concepts)}ä¸ªç›¸å…³æ¦‚å¿µ\n"
            for concept, info in list(relevant_concepts.items())[:3]:
                suggestions_text += f"   â€¢ {concept}: é¢‘æ¬¡{info['frequency']}, é‡è¦æ€§{info['importance']:.2f}\n"
                if info['related_concepts']:
                    suggestions_text += f"     ç›¸å…³æ¦‚å¿µ: {', '.join(info['related_concepts'])}\n"
        
        # åŸºäºä¼šè¯çŠ¶æ€çš„å»ºè®®
        session_count = context.get("session_memories_count", 0)
        if session_count > 10:
            suggestions_text += f"\nğŸ“ˆ **ä¼šè¯æ·±åº¦**: å·²è¿›è¡Œ{session_count}è½®äº¤äº’ï¼Œå»ºè®®é€‚æ—¶æ€»ç»“è¦ç‚¹\n"
        elif session_count < 3:
            suggestions_text += f"\nğŸŒŸ **æ¢ç´¢å»ºè®®**: å¯ä»¥å°è¯•ä¸åŒç±»å‹çš„äº¤äº’ï¼Œè®©æˆ‘æ›´å¥½åœ°äº†è§£æ‚¨çš„éœ€æ±‚\n"
        
        return suggestions_text
    
    def _generate_smart_suggestions(self, context: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½å»ºè®®åˆ—è¡¨"""
        suggestions = []
        
        # åŸºäºè®°å¿†æ¨¡å¼ç”Ÿæˆå»ºè®®
        memory_patterns = context.get("memory_patterns", {})
        if memory_patterns and memory_patterns != {"pattern": "no_data"}:
            importance_dist = memory_patterns.get("importance_distribution", {})
            
            if importance_dist.get("é«˜", 0) > importance_dist.get("ä¸­", 0):
                suggestions.append("ç»§ç»­å…³æ³¨é«˜ä»·å€¼å†…å®¹ï¼Œä¿æŒå­¦ä¹ æ·±åº¦")
            elif importance_dist.get("ä½", 0) > importance_dist.get("é«˜", 0):
                suggestions.append("å»ºè®®æå‡å†…å®¹è´¨é‡ï¼Œèšç„¦æ ¸å¿ƒæŠ€æœ¯é—®é¢˜")
        
        # åŸºäºçŸ¥è¯†å›¾è°±ç”Ÿæˆå»ºè®®
        knowledge_insights = context.get("knowledge_insights", {})
        total_concepts = knowledge_insights.get("total_concepts", 0)
        
        if total_concepts < 5:
            suggestions.append("æ¢ç´¢æ›´å¤šæŠ€æœ¯é¢†åŸŸï¼Œæ‰©å±•çŸ¥è¯†å›¾è°±")
        elif total_concepts > 20:
            suggestions.append("çŸ¥è¯†å›¾è°±ä¸°å¯Œï¼Œå¯ä»¥å¼€å§‹æ·±åº¦å…³è”åˆ†æ")
        
        # åŸºäºå»ºè®®æ ‡ç­¾ç”Ÿæˆå»ºè®®
        suggested_tags = context.get("suggested_tags", [])
        if suggested_tags:
            suggestions.append(f"æ¢ç´¢ç›¸å…³æ¦‚å¿µ: {', '.join(suggested_tags[:3])}")
        
        # é»˜è®¤å»ºè®®
        if not suggestions:
            suggestions = [
                "å°è¯•åˆ›å»ºä¸€ä¸ªæŠ€æœ¯å­¦ä¹ ä»»åŠ¡",
                "æœç´¢ç›¸å…³çš„å†å²è®°å¿†",
                "æŸ¥çœ‹ç³»ç»Ÿæ€§èƒ½å’Œè®°å¿†ç»Ÿè®¡"
            ]
        
        return suggestions
    
    async def process_query(self, query: str) -> AgentResponse:
        """å¤„ç†æŸ¥è¯¢çš„ä¸»è¦å…¥å£ç‚¹"""
        print(f"ğŸ¤– [{self.agent_name}] æ”¶åˆ°æŸ¥è¯¢: {query}")
        
        try:
            # æ€è€ƒè¿‡ç¨‹
            thinking_result = self.think(query)
            
            # æ ¹æ®æ€è€ƒç»“æœæ‰§è¡Œæ“ä½œ
            success = True
            message = thinking_result["conclusion"]
            
            # å¦‚æœéœ€è¦åˆ›å»ºä»»åŠ¡
            if "åˆ›å»ºä»»åŠ¡" in thinking_result.get("strategy", {}).get("next_actions", []):
                task_id = self.create_task(f"å¤„ç†æŸ¥è¯¢: {query[:30]}...", query)
                message += f"\\nå·²åˆ›å»ºä»»åŠ¡ {task_id}"
            
            # æ„å»ºå“åº”
            response = AgentResponse(
                success=success,
                message=message,
                data={
                    "thinking_process": thinking_result["steps"],
                    "confidence": thinking_result["confidence"],
                    "session_id": self.current_session_id
                },
                suggestions=["åŸºäºä¸Šä¸‹æ–‡çš„å»ºè®®1", "åŸºäºè®°å¿†çš„å»ºè®®2"],
                next_actions=thinking_result.get("strategy", {}).get("next_actions", [])
            )
            
            # è®°å½•æŸ¥è¯¢å¤„ç†
            self.memory_system.add_memory_with_analysis(
                f"å¤„ç†æŸ¥è¯¢: {query} -> {message[:100]}...",
                memory_type="interaction",
                importance=0.7,
                tags=["æŸ¥è¯¢", "å“åº”"],
                metadata={
                    "query": query,
                    "confidence": thinking_result["confidence"],
                    "thinking_steps": len(thinking_result["steps"])
                }
            )
            
            return response
            
        except Exception as e:
            self.state = AgentState.ERROR
            error_msg = f"å¤„ç†æŸ¥è¯¢æ—¶å‡ºé”™: {str(e)}"
            print(f"âŒ {error_msg}")
            
            # è®°å½•é”™è¯¯
            self.memory_system.add_memory_with_analysis(
                error_msg,
                memory_type="error",
                importance=0.9,
                tags=["é”™è¯¯", "å¼‚å¸¸"],
                metadata={"error": str(e), "query": query}
            )
            
            return AgentResponse(
                success=False,
                message=error_msg,
                suggestions=["æ£€æŸ¥è¾“å…¥æ ¼å¼", "é‡æ–°å°è¯•"]
            )
    
    def shutdown(self):
        """ä¼˜é›…å…³é—­Agent"""
        print(f"ğŸ”„ {self.agent_name} æ­£åœ¨å…³é—­...")
        
        # ä¿å­˜æ€§èƒ½ç»Ÿè®¡
        performance_file = self.workspace_dir / "performance_history.json"
        try:
            history = []
            if performance_file.exists():
                with open(performance_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)
            
            history.append({
                "session_id": self.current_session_id,
                "timestamp": time.time(),
                "performance": self.get_performance_report()
            })
            
            with open(performance_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜æ€§èƒ½ç»Ÿè®¡å¤±è´¥: {e}")
        
        # å…³é—­è®°å¿†ç³»ç»Ÿ
        self.memory_system.close()
        
        print(f"âœ… {self.agent_name} å·²å®‰å…¨å…³é—­")


# æµ‹è¯•ä»£ç 
async def test_baozong_agent():
    """æµ‹è¯•å®æ€»çš„SuperAgent"""
    print("ğŸš€ å®æ€»çš„SuperAgentæµ‹è¯•å¼€å§‹ï¼")
    
    # åˆ›å»ºAgentå®ä¾‹
    agent = BaozongSuperAgent("å®æ€»çš„æµ‹è¯•Agent")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å¸®æˆ‘åˆ†æä¸€ä¸‹Pythoné¡¹ç›®çš„æœ€ä½³å®è·µ",
        "å¦‚ä½•ä¼˜åŒ–AI Agentçš„æ€§èƒ½",
        "åˆ›å»ºä¸€ä¸ªä»£ç å®¡æŸ¥çš„ä»»åŠ¡",
        "ä»€ä¹ˆæ˜¯æ··åˆè®°å¿†ç³»ç»Ÿ",
        "æˆ‘éœ€è¦å­¦ä¹ LangChainæ¡†æ¶"
    ]
    
    print(f"\\nğŸ“ å¤„ç† {len(test_queries)} ä¸ªæµ‹è¯•æŸ¥è¯¢...")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\\n--- æŸ¥è¯¢ {i}/{len(test_queries)} ---")
        response = await agent.process_query(query)
        
        print(f"æˆåŠŸ: {response.success}")
        print(f"å“åº”: {response.message}")
        if response.suggestions:
            print(f"å»ºè®®: {', '.join(response.suggestions)}")
        
        # çŸ­æš‚å»¶è¿Ÿ
        await asyncio.sleep(1)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\\nğŸ“Š æ€§èƒ½æŠ¥å‘Š:")
    report = agent.get_performance_report()
    print(json.dumps(report, indent=2, ensure_ascii=False))
    
    # å…³é—­Agent
    agent.shutdown()
    print("\\nâœ… æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(test_baozong_agent())
